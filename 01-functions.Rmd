# Common Functions 

```{r include=FALSE}
library(tidyverse)
```


## For working with dataframes

I've scraped some data from r/psychologystudents so we can explore what we like to complain about. 

```{r include=FALSE}
psych_df <- read.csv("data/psychologystudents_20240820.csv")
```

```{r}
head(psych_df)
```

That's a bit chunky, why not we get rid of some variables? 

### select()

The select() function allows you retain specific columns (variables) by name from a dataframe. 

```{r}
psych_df %>%
  select(title) %>%
  head()
```

You can also pick out multiple columns by adding more arguments to the select() function.

```{r}
psych_df %>%
  select(score, id, subreddit) %>%
  head()
```

You can also retain columns by their numerical order. Here, the score, id, and subreddit are columns 3, 4, and 5 respectively.

```{r eval=FALSE}
psych_df %>%
  select(c(3:5)) %>%
  head()
```

### filter()

Recall that to call upon specific rows we can do this: 

```{r}
psych_df[4:7,] %>%
  select(title)
```

Which outputs rows 4 to 7.  

The filter function allows you to select specific rows that fit one or multiple criterion in your dataframe.

To get titles that have a Reddit score of 25 or more:

```{r}
psych_df %>%
  filter(score > 25) %>%
  select(title, score)

```

You can also input multiple logical conditions by adding more operators such as & or |. 
For a score of more than 25 and a "Discussion" flair. 

```{r}
psych_df %>%
  filter(score > 25 & flair == "Discussion") %>%
  select(title, score, flair) 
```

For a score of 100 or more OR a "Study Megathread" flair. 

```{r}
psych_df %>%
  filter(score >= 100 | flair == "Study Megathread") %>%
  select(title, score, flair)
```

### arrange()

Say I would like to look at 5 entries with the highest score. We can use arrange() and the function desc() to sort the text entries in a descending order:

```{r}
psych_df %>%
  select(title, score) %>%
  arrange(desc(score))%>%
  head(5)
```

5 lowest scoring entries? Arrange() sorts the dataframe in ascending order by default:

```{r}
psych_df %>%
  select(title, score) %>%
  arrange((score))%>%
  head(5)
```

Oh, seems like there might be more than 5 entries that scored a zero. Let's count how many using count():

```{r}
psych_df %>%
  filter(score==0) %>%
  count(score)
```

Seems like there are 8 entries with the score of 0.

### rbind()

This function is a super useful one. It binds rows of two or more dataframes together. Let's say I have these two dataframes:

```{r, include=FALSE}
name <- c("Bellatrix Lestrange","Basilisk","Voldemort","Barty Crouch Sr.","Professor Quirrell")
died <- c("Deathly Hallows","Chamber of Secrets","Deathly Hallows","Goblet of Fire","Philosopher's Stone")
bad_people <- data.frame(name,died)

name <- c("Cedric Diggory","Remus Lupin","Alastor Moody","Albus Dumbledore","Sirius Black")
died <- c("Goblet of Fire","Deathly Hallows","Deathly Hallows","Half Blood Prince","Order of the Phoenix")
good_people <- data.frame(name,died)
```

```{r}
good_people
```
```{r}
bad_people
```
Now it's time to use the rbind() function to bind the datasets together into one dataset. BUT, before we do that, it's good practice to add 


```{r}
hp_characters <- rbind(good_people,bad_people)
hp_characters
```
Great, so the rows of the second dataset (bad_people) were now added underneath the rows of the first dataset (good_people). But wait, what if someone doesn't know the characters that well so can't distinguish which characters are good or bad? It is good practice to add an extra column to each of the datasets beforehand so that you know where this data came from. Let's do that again:

```{r}
good_people <- good_people%>%
  mutate(identity="good")

bad_people <- bad_people%>%
  mutate(identity="bad")

hp_characters <- rbind(good_people,bad_people)
hp_characters
```

That's better.

### cbind()

This function is similar to rbind(), but instead of rows, it binds the columns (the c in cbind) of the datasets together. I have another dataset (actually just a column) that contains info about the house each of these characters are in:

```{r, include = FALSE}
house <- c("Hufflepuff","Gryffindoor","Unknown","Gryfindoor","Gryffindoor","Slytherin","NA","Slytherin","Unknown","Ravenclaw")

house_info <- data.frame(house)
```

```{r}
house_info
```

Let's add it to the hp_characters dataset.

```{r}
hp_characters_info <- cbind(hp_characters,house_info)
hp_characters_info
```

Note: Make sure that the number of rows match, otherwise you will get an error :/. 

Also, both the rows and the columns just get appended in the order that they are in. So make sure you double check that the data is as you want it to be.

### write.csv()

This function is good for when you want to save a dataset that you have created/cleaned in R to your computer as a csv file (which you can then put on OSF or something). This is the syntax:

```{r}
write.csv(hp_characters_info,"./data/filename.csv")
```

Note: The "./data/filename.csv" part of the argument specifies the path to the directory where you want to save it, ending with your chosen file name. If you don't specify the path, it will save it in your current directory.


## For working with text

Let's go back to the r/psychologystudents dataset and see what tools for working with text we can use.

### gsub()

This function let's you substitute a string or the characters in a vector or a dataframe with another string. It's very useful for data cleaning. For example, many big datasets of online comments usually contain a lot of links (URLs). In most cases, we are not interested in those links, as they might interfere with our analyses (although sometimes they might also be interesting). There is a way to get rid of/replace things we are not interested in.

The syntax of gsub() is the following:

**gsub(pattern, replacement, x)**
  
  - pattern: The pattern or the string that you want to replace
  - replacement: A string you want to input instead of the pattern.
  - x: the dataset/column you want the replacement to happen


If we wanted to replace all hashtags with a blank space (basically just get rid of them) in the body column of our dataframe, we could do this:

```{r}
psych_df$body <- gsub("#","",psych_df$body)
```


It gets more complicated if you want to do more complex things. You can replace multiple patterns, or work with something called Regular Expressions (we have a separate tab on what regular expressions are because it sort of has its own lore).

For some more advanced pattern matching with gsub(), click [here](https://sqlpad.io/tutorial/mastering-pattern-replacement-gsub/) or surf the internet.


Here is an example for how to get rid of URLs in the psych_df dataset:

```{r}
psych_df$body <- gsub("http\\S+|www\\S+|https\\S+", "", psych_df$body)
```

Breakdown of the syntax:

1. `http`: This matches the literal string "http".

2. `\\S+`:
  - `\\S` matches any non-whitespace character. (In R, the backslash is escaped by doubling it, so \\S becomes \S in regex, where S stands for non-whitespace.)
  - The `+` means "one or more" of the preceding character (i.e., one or more non-whitespace characters). This matches the rest of the URL after "http" (like http://example.com).
  
3. `|` (OR operator): This allows for multiple patterns to be matched. It means "or", so the regex will match either the first part before |, or the part after it.

4. `www:` This matches the literal string "www". This pattern is to catch URLs that start with "www" but might not have "http" or "https" at the beginning.

5. `\\S+` (again): Similar to the explanation above, this matches the non-whitespace part of the URL after "www".

6. `https`: This matches the literal string "https".

7. `\\S+`: Again, this matches the rest of the URL after "https".

The gsub() function then removes these matches (i.e., replaces them with an empty string "").

### unnest_tokens()

This is a very handy one and Zach for sure had already mentioned it. Unnest_tokens() splits your desired text column into "tokens", one token per row. A token could be one word, or two words, or three, or sentences, or so on. This function is a good start for when you want to, say, count the instances of certain words, or do more interesting analyses, like find which words are unique to specific groups or datasets.


The basic syntax looks like this:

**unnest_tokens(dataframe, output, input)**

  - output: Output column to be created as string or symbol. This is usually something like "words" or "ngram".
  - input: Input column that gets split as string or symbol. This is the name of your column you want split, usually "text" or "body".
  
Let's try it on our psych_df data:

```{r}
library(tidytext) # this is where the function comes from

unnested <- psych_df %>%
  unnest_tokens(word,body)
```

Let's have a look at the first 10 rows of our newly created words column.

```{r}
head(unnested,10)%>%
  select(word)
```

Each word has it's own row now.

Cool, let's count the words and look at the most used ones:

```{r}
unnested %>%
  count(word, sort=TRUE)%>%
  top_n(10, n) # selects the top 10 by the count
```

Wow, amazing insights. Anyways.
(this is where stop words come in)

Let's load in a dataset with stop words (a set of commonly used words that are usually not interesting)

```{r}
data(stop_words)
```

Now, we will delete these stop words from our dataset by using the anti_join() function (see the dplyr package in the Useful Package section).

```{r}
unnested <- unnested %>%
  anti_join(stop_words)
```

Let's see what the most used words are now:

```{r}
unnested %>%
  count(word, sort=TRUE)%>%
  top_n(10, n)
```

**Unnest tokens can also work at the sentence level** 

We just need to specify that the unit we want to split by by specifying "token = ....."; Check the documentation for other units you can tokenize by. 

```{r}
psych_df %>%
  unnest_tokens(output = "sentence", input = "body", token = "sentences") %>%
  select(title, sentence) %>%
  head(5)
```







